{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "import scipy.signal\n",
    "from scipy import *\n",
    "import copy"
   ]
  },
  {
   "source": [
    "---\n",
    "# VIDEO: Mean-smooth a time series\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "srate = 1000\n",
    "time = np.arange(0,3,1/srate) # 3 seconds\n",
    "n = len(time)\n",
    "p = 15 # poles for random interpolation\n",
    "\n",
    "# noise level, measured in standard deviations\n",
    "noiseamp = 5\n",
    "\n",
    "# amplitude modulator and noise level\n",
    "ampl = np.interp(np.linspace(0,p,n), np.arange(0,p), np.random.rand(p)*30) # interpolate y = interp(x, xp, fp) where x is the coordinates for interpolation, xp are the poles, fp are the y-coordinates of the xp poles. Will return y which is the same length as x\n",
    "noise = noiseamp * np.random.randn(n)\n",
    "signal = ampl + noise\n",
    "\n",
    "print(np.linspace(0,p,n))\n",
    "print(np.arange(0,p))\n",
    "print(np.random.rand(p))\n",
    "\n",
    "# Plotting for debugging\n",
    "plt.plot(time, ampl)\n",
    "plt.show()\n",
    "plt.plot(time, noise)\n",
    "plt.show()\n",
    "plt.plot(time, signal)\n",
    "plt.show()\n",
    "\n",
    "# initialize filtered signal vector\n",
    "filtsig = np.zeros(n)\n",
    "\n",
    "# implement the running mean filter\n",
    "k = 50 # filter window is actually k*2+1 \n",
    "print(f\"range of filtsig = {range(k, n-k-1)}\")\n",
    "for i in range(k,n-k-1):\n",
    "    # each point is the average of k surrounding points\n",
    "    filtsig[i] = np.mean(signal[i-k:i+k])\n",
    "\n",
    "# compute window size in ms\n",
    "windowsize = 1000 * (k*2+1) / srate\n",
    "\n",
    "# plot the noisy and filtered signals\n",
    "plt.plot(time, signal, label='orig')\n",
    "plt.plot(time, filtsig, label='filtered')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.title('Running-mean filter with a k=%d=ms' %windowsize)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "source": [
    "---\n",
    "# VIDEO: Gaussian-smooth a time series\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create signal\n",
    "srate = 1000 # Hz\n",
    "time = np.arange(0,3,1/srate)\n",
    "n = len(time)\n",
    "p = 15 # poles for random interpolation\n",
    "\n",
    "# noise level, measured in standard deviations\n",
    "noiseamp = 5\n",
    "\n",
    "# amplitude modulator and noise level\n",
    "ampl = np.interp(linspace(1,p,n), np.arange(0,p), np.random.rand(p)*30)\n",
    "noise = noiseamp * np.random.randn(n)\n",
    "signal = ampl + noise\n",
    "\n",
    "## Create Gaussian kernel\n",
    "# full-width half-maximum: the key Gaussian parameter\n",
    "fwhm = 25 # in ms\n",
    "\n",
    "# normalized time vector in ms \n",
    "k = 100\n",
    "gtime = 1000*np.arange(-k,k) / srate\n",
    "\n",
    "# create Gaussian window \n",
    "gauswin = np.exp(-(4*np.log(2)*gtime**2) / fwhm**2)\n",
    "\n",
    "# compute empirical FWHM \n",
    "pstPeakHalf = k+np.argmin((gauswin[k:]-0.5)**2) # find the index in gaussian window corresponding to half the maximum value, then square it because there are positive and negative values \n",
    "prePeakHalf = np.argmin((gauswin-0.5)**2) # do the same thing but for the first half of the gaussian window before the peak \n",
    "\n",
    "empFWHM = gtime[pstPeakHalf] - gtime[prePeakHalf]\n",
    "\n",
    "# show the Gaussian \n",
    "plt.plot(gtime, gauswin, 'ko-')\n",
    "plt.plot([gtime[prePeakHalf],gtime[pstPeakHalf]], [gauswin[prePeakHalf], gauswin[pstPeakHalf]], 'm')\n",
    "\n",
    "# then normalize Gaussian to unit energy\n",
    "gauswin = gauswin / np.sum(gauswin)\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Gain')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## implement the filter\n",
    "\n",
    "# initialize filtered signal vector\n",
    "filtsigG = copy.deepcopy(signal)\n",
    "\n",
    "# implement the gaussian window filter\n",
    "for i in range(k+1, n-k-1):\n",
    "    # each point is the weighted average of k surrounding points\n",
    "    filtsigG[i] = np.sum(signal[i-k:i+k] * gauswin)\n",
    "\n",
    "# plot\n",
    "plt.plot(time, signal,  'r', label='Original')\n",
    "plt.plot(time, filtsigG, 'k', label='Gaussian-filtered')\n",
    "\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('amp. (a.u.')\n",
    "plt.legend()\n",
    "plt.title('Gaussian smoothing filter')\n",
    "\n",
    "## for comparison, plot mean smoothing filter\n",
    "\n",
    "# initialize filtered signal vector \n",
    "filtsigMean = copy.deepcopy(signal)\n",
    "\n",
    "# implement the running mean filter\n",
    "# note: using mk instead of k to avoid confusion with k above\n",
    "mk = 20 # filter window is actually mk*2+1\n",
    "for i in range(mk+1, n-mk-1):\n",
    "    # each point is the average of k surrounding points\n",
    "    filtsigMean[i] = mean(signal[i-mk:i+mk])\n",
    "plt.plot(time, filtsigMean, 'b', label='Running mean')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "---\n",
    "# VIDEO: Gaussian-smooth a spike time series\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate time series of random spikes\n",
    "\n",
    "# number of spikes\n",
    "n = 300 \n",
    "\n",
    "# inter-spike intervals (exponential distribution for bursts)\n",
    "isi = np.round(np.exp(np.random.randn(n))*10) # this generates an exponential distribution where there is are a lot of short interspike intervals but less longer interspike intervals \n",
    "plt.hist(isi)\n",
    "plt.show()\n",
    "\n",
    "# generate spike time series\n",
    "spikets = np.zeros(int(sum(isi))) # add up all the interspike intervals to get the total length of the time vector\n",
    "\n",
    "for i in range(0, n):\n",
    "    spikets[int(np.sum(isi[0:i]))] = 1 # loop through each interspike interval value and set to 1. Add them up one by one as you go through the loop to get the right spike times\n",
    "\n",
    "# plot\n",
    "plt.plot(spikets)\n",
    "plt.xlabel('Time (a.u.)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create and implement Gaussian window\n",
    "\n",
    "# full-width half-maximum: the key Gaussian parameter\n",
    "fwhm = 25 # in points\n",
    "\n",
    "# normalized time vector in ms\n",
    "k = 100\n",
    "gtime = np.arange(-k,k)\n",
    "\n",
    "# create Gaussian window\n",
    "gauswin = np.exp(-(4*log(2)*gtime**2) / fwhm**2)\n",
    "gauswin = gauswin / np.sum(gauswin)\n",
    "\n",
    "# initialize filtered signal vector\n",
    "filtsigG = np.zeros(len(spikets))\n",
    "\n",
    "# implement filtered signal vector\n",
    "filtsigG = np.zeros(len(spikets))\n",
    "\n",
    "# implement the weighted running mean filter\n",
    "for i in range(k+1, len(spikets)-k-1):\n",
    "    filtsigG[i] = np.sum(spikets[i-k:i+k] * gauswin)\n",
    "\n",
    "# plot the filtered signal (spike probability density)\n",
    "plt.plot(spikets, 'b', label='spikes')\n",
    "plt.plot(filtsigG, 'r', label='spike p.d.')\n",
    "plt.legend()\n",
    "plt.title('Spikes and spike probability density')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "---\n",
    "# VIDEO: Denoising via TKEO\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "emgdata = sio.loadmat('emg4TKEO.mat')\n",
    "\n",
    "# extract needed variables\n",
    "emgtime = emgdata['emgtime'][0]\n",
    "emg = emgdata['emg'][0]\n",
    "\n",
    "# initialize filtered signal\n",
    "emgf = copy.deepcopy(emg)\n",
    "\n",
    "# the loop version for interpretability\n",
    "for i in range(1, len(emgf)-1):\n",
    "    emgf[i] = emg[i]**2 - emg[i-1]*emg[i+1]\n",
    "\n",
    "\n",
    "# the vectorized version for speed and elegance\n",
    "emgf2 = copy.deepcopy(emg)\n",
    "emgf2[1:-1] = emg[i:-1]**2 - emg[0:-2]*emg[2:] # three vectors, main vector gets squared from 1 to end-1 and you subtract the product of the vector that starts at 0 and ends at end-2 multiplied by the time point ahead which starts at 2 and ends with the last time point\n",
    "\n",
    "## convert both signal to zscore\n",
    "\n",
    "# find timepoint zero\n",
    "time0 = np.argmin(emgtime**2)\n",
    "\n",
    "# convert original EMG to z-score from time-zero\n",
    "emgZ = (emg-np.mean(emg[0:time0])) / np.std(emg[0:time0])\n",
    "\n",
    "# same for filtered EMG energy\n",
    "emgZf = (emgf - np.mean(emgf[0:time0])) / std(emgf[0:time0])\n",
    "\n",
    "## plot\n",
    "# plot \"raw\" (normalized to max. 1)\n",
    "plt.plot(emgtime, emg/np.max(emg), 'b', label='EMG')\n",
    "plt.plot(emgtime, emgf/np.max(emgf), 'm', label='TKEO energy')\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Amplitude or energy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# plot zscored\n",
    "plt.plot(emgtime, emgZ, 'b', label='EMG')\n",
    "plt.plot(emgtime, emgZf, 'm', label='TKEO Energy')\n",
    "\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Zscore relative to pre-stimulus')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "---\n",
    "# VIDEO: Median filter to remove spike noise\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create signal \n",
    "n = 2000\n",
    "signal = np.cumsum(np.random.randn(n))\n",
    "\n",
    "# proportion of time points to replace with noise\n",
    "propnoise = 0.05\n",
    "\n",
    "# find noise points\n",
    "noisepnts = np.random.permutation(n) # randomly reorder time points\n",
    "print(noisepnts)\n",
    "noisepnts = noisepnts[0:int(n*propnoise)] # choose the first 0.05% of noise points\n",
    "print(noisepnts)\n",
    "\n",
    "\n",
    "# generate signal and replace points with noise\n",
    "signal[noisepnts] = 50 + np.random.rand(len(noisepnts))*100 \n",
    "\n",
    "plt.plot(signal)\n",
    "plt.show()\n",
    "\n",
    "# use hist to pick threshold\n",
    "plt.hist(signal, 100)\n",
    "plt.show()\n",
    "\n",
    "# visual-picked threshold\n",
    "threshold = 40\n",
    "\n",
    "# find data values above the threshold \n",
    "suprathresh = np.where(signal > threshold)[0]\n",
    "\n",
    "# initialize the filtered signal \n",
    "filtsig = copy.deepcopy(signal)\n",
    "\n",
    "# loop through suprathreshold points and set to median of k\n",
    "k = 20 # actual window is k*2+1\n",
    "for ti in range(len(suprathresh)):\n",
    "\n",
    "    #lower and upper bounds\n",
    "    lowbnd = np.max((0, suprathresh[ti] - k))\n",
    "    uppbnd = np.min((suprathresh[ti]+k, n+1))\n",
    "\n",
    "    # compute median of surrounding points\n",
    "    filtsig[suprathresh[ti]] = np.median(signal[lowbnd:uppbnd])\n",
    "\n",
    "# plot\n",
    "plt.plot(range(0, n), signal, range(0, n), filtsig)\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "---\n",
    "# VIDEO: Remove linear trend\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create signal with linear trend imposed\n",
    "n = 2000\n",
    "signal = np.cumsum(np.random.randn(n)) + np.linspace(-30, 30, n)\n",
    "\n",
    "# linear detrending\n",
    "detsignal = scipy.signal.detrend(signal)\n",
    "\n",
    "# get means\n",
    "omean = np.mean(signal) # original mean\n",
    "dmean = np.mean(detsignal) # detrended mean\n",
    "\n",
    "# plot signal and detrended signal \n",
    "plt.plot(range(0, n), signal, label='Original, mean=%d' %omean)\n",
    "plt.plot(range(0, n), detsignal, label='Detrended, mean=%d' %dmean)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "--- \n",
    "# VIDEO: Remove nonlinear trend with polynomials\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## polynomial intuition\n",
    "\n",
    "order = 2 \n",
    "x = np.linspace(-15, 15, 100)\n",
    "\n",
    "y = np.zeros(len(x))\n",
    "\n",
    "for i in range(order+1):\n",
    "    y = y + np.random.randn(1)*x**i\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.title('Order-%d polynomial' %order)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate siganl with slow polynomial artifact\n",
    "\n",
    "n = 1000\n",
    "t = range(n)\n",
    "k = 10 # number of poles for random amplitudes\n",
    "\n",
    "slowdrift = np.interp(np.linspace(1, k, n), np.arange(0, k), 100*np.random.randn(k))\n",
    "signal = slowdrift + 20*np.random.randn(n)\n",
    "\n",
    "# plot\n",
    "plt.plot(t, signal)\n",
    "plt.xlabel('Time (a.u.)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fit a 3-order polynomial\n",
    "\n",
    "# polynomial fit (returns coefficients)\n",
    "p = polyfit(t, signal, 3)\n",
    "\n",
    "# predicted data is evaluation of polynomial\n",
    "yHat = polyval(p, t)\n",
    "\n",
    "# compute residual (the cleaned signal)\n",
    "residual = signal - yHat\n",
    "\n",
    "# now polt the fit (the function that will be removed)\n",
    "\n",
    "plt.plot(t, signal, 'b', label='Original')\n",
    "plt.plot(t, yHat, 'r', label='Polyfit')\n",
    "plt.plot(t, residual, 'k', label='Filtered signal')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bayes information criterion to find optimal order\n",
    "# possible orders\n",
    "orders = range(5, 40)\n",
    "\n",
    "# sum of squared errors (sse is reserved!)\n",
    "sse1 = np.zeros(len(orders))\n",
    "\n",
    "# loop through orders\n",
    "for ri in range(len(orders)):\n",
    "\n",
    "    # compute polynomial ( fitting time series)\n",
    "    yHat = np.polyval(polyfit(t, signal, orders[ri]), t)\n",
    "\n",
    "    # compute fit of model to data (sum of squared errors)\n",
    "    sse1[ri] = np.sum((yHat-signal)**2)/n\n",
    "\n",
    "# Bayes information criterion \n",
    "bic = n*np.log(sse1) + orders*np.log(n)\n",
    "\n",
    "# best parameter has lowest BIC\n",
    "bestP = min(bic)\n",
    "idx = np.argmin(bic)\n",
    "\n",
    "# plot the BIC\n",
    "plt.plot(orders, bic, 'ks-')\n",
    "plt.plot(orders[idx], bestP, 'ro')\n",
    "plt.xlabel('Polynomial order')\n",
    "plt.ylabel('Bayes information criterion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now repeat filter for best (smallest) BIC\n",
    "\n",
    "# polynomial fit\n",
    "polycoefs = polyfit(t, signal, orders[idx])\n",
    "\n",
    "# estimated data based on the coefficients \n",
    "yHat = polyval(polycoefs, t)\n",
    "\n",
    "# filtered signal is residual\n",
    "filtsig = signal - yHat\n",
    "\n",
    "## plotting\n",
    "plt.plot(t, signal, 'b', label='Original')\n",
    "plt.plot(t, yHat, 'r', label='Polynommial fit')\n",
    "plt.plot(t, filtsig, 'k', label='Filtered')\n",
    "\n",
    "plt.xlabel('Time (a.u.)')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "---\n",
    "# VIDEO: Averaging multiple repetitions (time-synchronous averaging)\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## simulate data\n",
    "\n",
    "# create event (derivative of Gaussian)\n",
    "k = 100 # duration of event in time points\n",
    "event = np.diff(np.exp(-np.linspace(-2,2,k+1)**2))\n",
    "event = event/np.max(event) # normalize to max = 1\n",
    "\n",
    "# event onset times\n",
    "Nevents = 30 \n",
    "onsettimes = np.random.permutation(10000 - k)\n",
    "onsettimes = onsettimes[0:Nevents]\n",
    "\n",
    "# put event into data\n",
    "data = np.zeros(10000)\n",
    "for ei in range(Nevents):\n",
    "    data[onsettimes[ei]:onsettimes[ei]+k] = event\n",
    "\n",
    "# add noise\n",
    "data = data + 0.5*np.random.randn(len(data))\n",
    "\n",
    "# plot data\n",
    "plt.subplot(211)\n",
    "plt.plot(data)\n",
    "\n",
    "# plot one event \n",
    "plt.subplot(212)\n",
    "plt.plot(range(k), data[onsettimes[3]:onsettimes[3]+k])\n",
    "plt.plot(range(k), event)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract all events into a matrix\n",
    "\n",
    "datamatrix = np.zeros((Nevents, k))\n",
    "\n",
    "for ei in range(0, Nevents):\n",
    "    datamatrix[ei, :] = data[onsettimes[ei]:onsettimes[ei]+k] # need to know what the onset times are, otherwise need template matching or pattern matching\n",
    "\n",
    "plt.imshow(datamatrix)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Event number')\n",
    "plt.title('All events')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(0, k), np.mean(datamatrix, axis=0), label='Averaged')\n",
    "plt.plot(range(0, k), event, label='Ground-truth')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Amplitude')\n",
    "plt.legend()\n",
    "plt.title('Average events')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "---\n",
    "# VIDEO: Remove artifact via least-squares template-matching\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "matdat = sio.loadmat('templateProjection.mat')\n",
    "EEGdat = matdat['EEGdat']\n",
    "eyedat = matdat['eyedat']\n",
    "timevec = matdat['timevec'][0]\n",
    "MN = np.shape(EEGdat) # matrix sizes\n",
    "\n",
    "# initalize residual data\n",
    "resdat = zeros(np.shape(EEGdat))\n",
    "\n",
    "# loop over trials\n",
    "for triali in range(0, MN[1]):\n",
    "\n",
    "    # build the least-squares model as intercept and EOG from this trial\n",
    "    X = np.column_stack((np.ones(MN[0]), eyedat[:, triali]))\n",
    "\n",
    "    # compute regression coefficients for EEG channel\n",
    "    b = np.linalg.solve(np.matrix.transpose(X)@X, np.matrix.transpose(X)@EEGdat[:, triali])\n",
    "\n",
    "    # predicted data\n",
    "    yHat = X@b\n",
    "\n",
    "    # new data are the residuals after projection out the best EKG fit\n",
    "    resdat[:, triali] = EEGdat[:, triali] - yHat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### plotting\n",
    "\n",
    "# trial averages\n",
    "plt.plot(timevec,np.mean(eyedat,axis=1),label='EOG')\n",
    "plt.plot(timevec,np.mean(EEGdat,axis=1),label='EEG')\n",
    "plt.plot(timevec,np.mean(resdat,1),label='Residual')\n",
    "\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show all trials in a map\n",
    "clim = [-1, 1]*20\n",
    "plt.subplot(131)\n",
    "plt.imshow(eyedat.T)\n",
    "plt.title('EOG')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(EEGdat.T)\n",
    "plt.title('EOG')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(resdat.T)\n",
    "plt.title('Residual')\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "---\n",
    "# Denoising Code Challenge\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load code challenge dataset \n",
    "challengedat = sio.loadmat('denoising_codeChallenge.mat')\n",
    "origSignal = challengedat['origSignal'][0] # need to include [0] for loading the array properly\n",
    "cleanedSignal = challengedat['cleanedSignal'][0]\n",
    "timevec = range(0,np.shape(origSignal)[0])\n",
    "\n",
    "# Plot original signal and cleaned signal\n",
    "plt.subplot(211)\n",
    "plt.plot(timevec, origSignal)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(timevec, cleanedSignal)\n",
    "\n",
    "#plt.plot(timevec, origSignal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Develop plan for removing noise\n",
    "# Probably want to remove the spikes with median filtering\n",
    "# Also likely want to pull out the slower oscillations. Might be good to look at FFT and filter out high frequency noise, then see where to go from there. "
   ]
  }
 ]
}